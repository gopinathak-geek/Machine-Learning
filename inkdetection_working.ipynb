{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuw0QX0dq7cXaA0Du5bdmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopinathak-geek/Machine-Learning/blob/main/inkdetection_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lkOvw7LfmWJ",
        "outputId": "0d3f4fc4-4584-4eca-a567-0385908089ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfXjxcXRfmNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "GDU8AQ4AdCJh",
        "outputId": "c879b319-c477-4886-8616-ca4ac2b55b23"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b8635d9402a6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import BinaryConfusionMatrix\n",
        "from torchmetrics.classification import BinaryAccuracy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler    \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "id": "pksuilZ2dNwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class FrameData:\n",
        "#     def __init__(self, path, space=''):\n",
        "#         self.path = path\n",
        "#         self.space = space\n",
        "#         self.mask = np.array(Image.open(self.path + \"/mask.png\").convert('1'))\n",
        "#         self.directory = self.path + \"/surface_volume\"\n",
        "#         self.filelist = glob.glob(os.path.join(self.directory, '*.tif'))\n",
        "    \n",
        "#     def TrainingData(self):\n",
        "#         ink_label = np.array(Image.open(self.path + \"/inklabels.png\").convert('1'))\n",
        "#         ink_label_index = np.where(ink_label == 1)\n",
        "#         mask_index = np.where(self.mask != ink_label)\n",
        "        \n",
        "#         random_index_ink_label = np.random.choice(ink_label_index[0], 1000, replace=False)  \n",
        "#         random_ink_label = ink_label_index[0][random_index_ink_label], ink_label_index[1][random_index_ink_label]\n",
        "        \n",
        "#         random_index_mask = np.random.choice(mask_index[0], len(random_ink_label[0])*3, replace=False)  \n",
        "#         random_mask = mask_index[0][random_index_mask], mask_index[1][random_index_mask]\n",
        "        \n",
        "#         indexes = np.concatenate([random_ink_label[0],random_mask[0]]), np.concatenate([random_ink_label[1],random_mask[1]])\n",
        "        \n",
        "#         files = {}\n",
        "#         for file in sorted(self.filelist): \n",
        "#             print(file)\n",
        "#             image = np.array(Image.open(file))\n",
        "#             image = image.astype('float32')\n",
        "#             value = image[indexes]\n",
        "#             files['x_'+Path(file).stem] = value\n",
        "        \n",
        "#         y_image = np.array(Image.open(self.path+'/inklabels.png'))\n",
        "#         y_image = y_image.astype('float32')\n",
        "#         y_value = y_image[indexes]\n",
        "#         files['y'] = y_value\n",
        "#         return pd.DataFrame(files)\n",
        "    \n",
        "#     def ValidationData(self):\n",
        "#         validation_mask = np.zeros(self.mask.shape, dtype=bool)\n",
        "#         validation_mask[self.space[1]:self.space[1]+self.space[3]+1, self.space[0]:self.space[0]+self.space[2]+1] = True\n",
        "#         indexes = np.where(validation_mask == 1)\n",
        "\n",
        "#         files = {}\n",
        "#         for file in sorted(self.filelist): \n",
        "#             print(file)\n",
        "#             image = np.array(Image.open(file))\n",
        "#             image = image.astype('float32')\n",
        "#             value = image[indexes]\n",
        "#             files['x_'+Path(file).stem] = value\n",
        "        \n",
        "#         y_image = np.array(Image.open(self.path+'/inklabels.png'))\n",
        "#         y_image = y_image.astype('float32')\n",
        "#         y_value = y_image[indexes]\n",
        "#         files['y'] = y_value\n",
        "#         return pd.DataFrame(files)\n",
        "        \n",
        "    "
      ],
      "metadata": {
        "id": "hX93BIsqdNtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_1 = FrameData('/kaggle/input/vesuvius-challenge-ink-detection/train/1')\n",
        "# training_data_1 = train_data_1.TrainingData()"
      ],
      "metadata": {
        "id": "WpIYsNkGdNp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_2 = FrameData('/kaggle/input/vesuvius-challenge-ink-detection/train/2')\n",
        "# training_data_2 = train_data_2.TrainingData()"
      ],
      "metadata": {
        "id": "J5LOzSWGdNme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_data = pd.concat([training_data_1, training_data_2])"
      ],
      "metadata": {
        "id": "hf7AWVyxdNHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# valid_data_3 = FrameData('/kaggle/input/vesuvius-challenge-ink-detection/train/3', (1000, 4500, 1000, 1000))\n",
        "# validation_data_3 = valid_data_3.ValidationData()"
      ],
      "metadata": {
        "id": "blZPqYLWdrwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_x = training_data.drop(['y'], axis=1)\n",
        "# train_y = training_data['y']\n",
        "# valid_x = validation_data_3.drop(['y'], axis=1)\n",
        "# valid_y = validation_data_3['y']"
      ],
      "metadata": {
        "id": "n6FfgDAQdyTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = StandardScaler()\n",
        "# train_x = scaler.fit_transform(train_x)\n",
        "# valid_x = scaler.transform(valid_x)"
      ],
      "metadata": {
        "id": "g-k1ekUPdyQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Logistic Regression\n",
        "# LogisticModel = LogisticRegression()\n",
        "# LogisticModel.fit(train_x, train_y)\n",
        "# LogisticScore = LogisticModel.score(valid_x, valid_y)\n",
        "# LogisticPredictions = LogisticModel.predict(valid_x)\n",
        "# LogisticCm = metrics.confusion_matrix(valid_y, LogisticPredictions)\n",
        "# print(f'Score:{LogisticScore} | cm:{LogisticCm}')"
      ],
      "metadata": {
        "id": "C7aM8nURdyMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Support vector machine\n",
        "# svmModel = svm.SVC(kernel='linear') # Linear Kernel\n",
        "# svmModel.fit(train_x, train_y)\n",
        "# SvmScore = svmModel.score(valid_x, valid_y)\n",
        "# SvmPredictions = svmModel.predict(valid_x)\n",
        "# SvmCm = metrics.confusion_matrix(valid_y, SvmPredictions)\n",
        "# print(f'Score:{SvmScore} | cm:{SvmCm}')"
      ],
      "metadata": {
        "id": "jjN4BjNhdyIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Naive bayes\n",
        "# NbModel = GaussianNB()\n",
        "# NbModel.fit(train_x, train_y)\n",
        "# NbScore = NbModel.score(valid_x, valid_y)\n",
        "# NbPredictions = NbModel.predict(valid_x)\n",
        "# NbCm = metrics.confusion_matrix(valid_y, NbPredictions)\n",
        "# print(f'Score:{NbScore} | cm:{NbCm}')"
      ],
      "metadata": {
        "id": "W77QMvixdyFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Random Forest\n",
        "# RandomForestModel = RandomForestClassifier()\n",
        "# RandomForestModel.fit(train_x, train_y)\n",
        "# RandomForestScore = RandomForestModel.score(valid_x, valid_y)\n",
        "# RandomForestPredictions = RandomForestModel.predict(valid_x)\n",
        "# RandomForestCm = metrics.confusion_matrix(valid_y, RandomForestPredictions)\n",
        "# print(f'Score:{RandomForestScore} | cm:{RandomForestCm}')"
      ],
      "metadata": {
        "id": "ulfcg1HCdyB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generateValidationImagePandas(path, rect, y):\n",
        "#     mask = np.array(Image.open(path + \"/mask.png\").convert('1'))\n",
        "#     image= np.zeros(mask.shape, dtype=float)\n",
        "#     y_image= np.zeros(mask.shape, dtype=float)\n",
        "#     y_image[rect[1]:rect[1]+rect[3]+1, rect[0]:rect[0]+rect[2]+1] = True\n",
        "#     image = image.astype('float32')\n",
        "#     index = np.where(y_image == 1)\n",
        "\n",
        "#     image[index] = y\n",
        "#     return F.to_pil_image(torch.from_numpy(image))"
      ],
      "metadata": {
        "id": "IIhLEVy0dx-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generateValidationImagePandas(\"/kaggle/input/vesuvius-challenge-ink-detection/train/3\", (1000, 4500, 1000, 1000), valid_y )"
      ],
      "metadata": {
        "id": "JVXa3u9Tdx7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generateValidationImagePandas(\"/kaggle/input/vesuvius-challenge-ink-detection/train/3\", (1000, 4500, 1000, 1000), LogisticPredictions )"
      ],
      "metadata": {
        "id": "rDpLJabrdx4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateValidationImage(path, indexes, y):\n",
        "    convert_tensor = transforms.ToTensor()\n",
        "    mask_image = Image.open(path + \"/mask.png\")\n",
        "    mask_tensor = convert_tensor(mask_image).to(DEVICE)\n",
        "    y_image_tensor = torch.zeros_like(mask_tensor).float()\n",
        "    y_image_tensor[indexes] = torch.squeeze(y, 1)\n",
        "    y_image_tensor = (y_image_tensor > 0).float()\n",
        "    return F.to_pil_image(y_image_tensor)"
      ],
      "metadata": {
        "id": "1iasDsuOdx0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateTestingImage(path, y):\n",
        "    convert_tensor = transforms.ToTensor()\n",
        "    mask_image = Image.open(path + \"/mask.png\")\n",
        "    mask_tensor = convert_tensor(mask_image).to(DEVICE)\n",
        "    indexes = torch.where(mask_tensor > 0)\n",
        "    y_image_tensor = torch.zeros_like(mask_tensor).float()\n",
        "    y_image_tensor[indexes] = torch.squeeze(y, 1)\n",
        "    y_image_tensor = (y_image_tensor > 0).float()\n",
        "    return F.to_pil_image(y_image_tensor)"
      ],
      "metadata": {
        "id": "XmuRkqF_dxx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InkDetectionDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ],
      "metadata": {
        "id": "CMy00Oa9dxub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InkDetectionTestDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ],
      "metadata": {
        "id": "K0s8Ms5_dxrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InkDetection:\n",
        "    def __init__(self, path, space=''):\n",
        "        self.path = path\n",
        "        self.space = space\n",
        "        self.directory = self.path + \"/surface_volume\"\n",
        "        self.filelist = glob.glob(os.path.join(self.directory, '*.tif'))\n",
        "        self.convert_tensor = transforms.ToTensor()\n",
        "        self.mask_tensor = self.convert_tensor(Image.open(self.path + \"/mask.png\")).to(DEVICE)\n",
        "        self.reference_image_tensor = self.convert_tensor(Image.open(\"/kaggle/input/vesuvius-challenge-ink-detection/train/1/surface_volume/00.tif\")).to(DEVICE)\n",
        "        self.imgToTensor = transforms.Compose([\n",
        "            transforms.Normalize(torch.mean(self.reference_image_tensor), torch.std(self.reference_image_tensor))\n",
        "        ])\n",
        "        \n",
        "    def TrainingData(self):        \n",
        "        ink_label_tensor = self.convert_tensor(Image.open(self.path + \"/inklabels.png\")).to(DEVICE)\n",
        "\n",
        "        # index of ink in the inklabel\n",
        "        ink_i,ink_j,ink_k = torch.where(ink_label_tensor > 0)\n",
        "\n",
        "        #index of boundary\n",
        "        mask_i,mask_j,mask_k = torch.where(self.mask_tensor != ink_label_tensor)\n",
        "        \n",
        "        # index of the randomly selected mask which is equal length of ink \n",
        "        random_index_ink = torch.randperm(1000)[:ink_i.shape[0]].to(DEVICE) \n",
        "        random_index_mask = torch.randperm(3000)[:mask_i.shape[0]].to(DEVICE) \n",
        "        \n",
        "        index = torch.cat((ink_i[random_index_ink],mask_i[random_index_mask])).to(DEVICE), torch.cat((ink_j[random_index_ink],mask_j[random_index_mask])).to(DEVICE), torch.cat((ink_k[random_index_ink],mask_k[random_index_mask])).to(DEVICE)\n",
        "    \n",
        "        array_x = []\n",
        "        for file in sorted(self.filelist): \n",
        "            image_tensor = self.convert_tensor(Image.open(file)).to(DEVICE)\n",
        "            image_tensor = self.imgToTensor(image_tensor.float()).to(DEVICE)\n",
        "            x = image_tensor[index].to(DEVICE)\n",
        "            x = x[None, :]\n",
        "            xt = torch.transpose(x, 0, 1).to(DEVICE)\n",
        "            array_x.append(xt)\n",
        "        x = torch.cat(array_x, dim=1).to(DEVICE)\n",
        "        \n",
        "        y_t = ink_label_tensor[index].to(DEVICE)\n",
        "        y_t = y_t[None, :]\n",
        "        y = torch.transpose(y_t, 0, 1).to(DEVICE)\n",
        "        y = (y > 0).float()\n",
        "        return x, y\n",
        "    \n",
        "    def ValidationData(self):\n",
        "        mask_validation_tensor = torch.zeros_like(self.mask_tensor).float()\n",
        "        mask_validation_tensor[0, self.space[1]:self.space[1]+self.space[3]+1, self.space[0]:self.space[0]+self.space[2]+1] = 1.0\n",
        "        index = torch.where(mask_validation_tensor > 0)\n",
        "        \n",
        "        array_x = []\n",
        "        for file in sorted(self.filelist): \n",
        "            image_tensor = self.convert_tensor(Image.open(file)).to(DEVICE)\n",
        "            image_tensor = self.imgToTensor(image_tensor.float()).to(DEVICE)\n",
        "            x = image_tensor[index].to(DEVICE)\n",
        "            x = x[None, :]\n",
        "            xt = torch.transpose(x, 0, 1).to(DEVICE)\n",
        "            array_x.append(xt)\n",
        "        x = torch.cat(array_x, dim=1).to(DEVICE)\n",
        "        \n",
        "        ink_label_tensor = self.convert_tensor(Image.open(self.path + \"/inklabels.png\")).to(DEVICE)\n",
        "        y_t = ink_label_tensor[index].to(DEVICE)\n",
        "        y_t = y_t[None, :]\n",
        "        y = torch.transpose(y_t, 0, 1).to(DEVICE)\n",
        "        y = (y > 0).float()\n",
        "        return x, y, index\n",
        "    \n",
        "    def TestingData(self):\n",
        "        index = torch.where(self.mask_tensor > 0)\n",
        "        array_x = []\n",
        "        for file in sorted(self.filelist): \n",
        "            image_tensor = self.convert_tensor(Image.open(file)).to(DEVICE)\n",
        "            image_tensor = self.imgToTensor(image_tensor.float()).to(DEVICE)\n",
        "            x = image_tensor[index].to(DEVICE)\n",
        "            x = x[None, :]\n",
        "            xt = torch.transpose(x, 0, 1).to(DEVICE)\n",
        "            array_x.append(xt)\n",
        "        x = torch.cat(array_x, dim=1).to(DEVICE)\n",
        "        return x\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "NpdIB8fPdxnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = InkDetection('/kaggle/input/vesuvius-challenge-ink-detection/train/1')\n",
        "training_data_1 = data_1.TrainingData()\n",
        "training_data_1"
      ],
      "metadata": {
        "id": "iBk30b9LdxjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_3 = InkDetection('/kaggle/input/vesuvius-challenge-ink-detection/train/3')\n",
        "training_data_3 = data_3.TrainingData()\n",
        "training_data_3"
      ],
      "metadata": {
        "id": "_ElhFU3Vee1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torch.cat((training_data_1[0],training_data_3[0]), dim=0).to(DEVICE), torch.cat((training_data_1[1],training_data_3[1]), dim=0).to(DEVICE)"
      ],
      "metadata": {
        "id": "r82zxWVfeeyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "mask = Image.open(\"/kaggle/input/vesuvius-challenge-ink-detection/train/2/inklabels.png\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(mask, cmap='gray')\n",
        "# rect = (1000, 4500, 1000, 1000)\n",
        "rect = (3500, 3500, 700, 950)\n",
        "patch = patches.Rectangle((rect[0], rect[1]), rect[2], rect[3], linewidth=2, edgecolor='r', facecolor='none')\n",
        "ax.add_patch(patch)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1MgZ_Ix2eevF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2 = InkDetection('/kaggle/input/vesuvius-challenge-ink-detection/train/2', space=(3500, 3500, 700, 950))\n",
        "validation_data_2 = data_2.ValidationData()\n",
        "validation_data_2"
      ],
      "metadata": {
        "id": "oA5sh3b9eesC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = InkDetectionDataset(training_data[0], training_data[1])\n",
        "valid_data = InkDetectionDataset(validation_data_2[0], validation_data_2[1])"
      ],
      "metadata": {
        "id": "j5pyzBYpeeop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_size = int(0.8 * len(train_data))\n",
        "# val_size = len(train_data) - train_size\n",
        "# training_data, validation_data = torch.utils.data.random_split(train_data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "QuZQ28y_eelf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "QmsRtCdGeeiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(dataset=valid_data, batch_size=len(valid_data))"
      ],
      "metadata": {
        "id": "FlN10f-Xeeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "    def forward(self, x):\n",
        "        y_predicted = torch.sigmoid(self.linear(x))\n",
        "        return y_predicted"
      ],
      "metadata": {
        "id": "B_17fuSqeebl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(65).to(DEVICE)"
      ],
      "metadata": {
        "id": "p5ZFovTqeeYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "alRu4EnNeeUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for x, y in training_loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        #forward pass\n",
        "        y_prediction = model(x)\n",
        "        loss = criterion(y_prediction, y)\n",
        "\n",
        "        #Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad() \n",
        "    \n",
        "    if(epoch+1) % 10 ==1:\n",
        "        print(f'epoch: {epoch+1} | loss = {loss.item():4f}')\n",
        "        \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in validation_loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        y_prediction = model(x)\n",
        "        prediction = y_prediction.round()\n",
        "        metric = BinaryAccuracy().to(DEVICE)\n",
        "        accuracy = metric(prediction, y)\n",
        "        bcm = BinaryConfusionMatrix().to(DEVICE)\n",
        "        cm = bcm(prediction, y)\n",
        "        print(f'accuracy:{accuracy:4f} | cm:{cm}')"
      ],
      "metadata": {
        "id": "gY8jKTXxeeRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GenerateValidationImage('/kaggle/input/vesuvius-challenge-ink-detection/train/2',validation_data_2[2], prediction)"
      ],
      "metadata": {
        "id": "bwCfTPKHeeNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_a = InkDetection('/kaggle/input/vesuvius-challenge-ink-detection/test/a')\n",
        "test_data_b = InkDetection('/kaggle/input/vesuvius-challenge-ink-detection/test/b')\n",
        "\n",
        "testing_data_a = test_data_a.TestingData()\n",
        "testing_data_b = test_data_b.TestingData()"
      ],
      "metadata": {
        "id": "i4EPIIEhfEd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_a = InkDetectionTestDataset(testing_data_a)\n",
        "data_b = InkDetectionTestDataset(testing_data_b)"
      ],
      "metadata": {
        "id": "Od8VJacbfEa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_a_loader = DataLoader(dataset=data_a, batch_size=len(data_a))\n",
        "data_b_loader = DataLoader(dataset=data_b, batch_size=len(data_b))"
      ],
      "metadata": {
        "id": "uEnCFoeZfEYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() \n",
        "with torch.no_grad():\n",
        "    for x in data_a_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        a_y_pred = model(x)\n",
        "        a_prediction = a_y_pred.round()"
      ],
      "metadata": {
        "id": "GCccGOTdfEU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() \n",
        "with torch.no_grad():\n",
        "    for x in data_b_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        b_y_pred = model(x)\n",
        "        b_prediction = b_y_pred.round()"
      ],
      "metadata": {
        "id": "mV97rkgefERx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GenerateTestingImage('/kaggle/input/vesuvius-challenge-ink-detection/test/a',a_prediction)"
      ],
      "metadata": {
        "id": "dFS-02BCfEOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GenerateTestingImage('/kaggle/input/vesuvius-challenge-ink-detection/test/b',b_prediction)"
      ],
      "metadata": {
        "id": "lMH8ZapSfEKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_image = GenerateTestingImage('/kaggle/input/vesuvius-challenge-ink-detection/test/a',a_prediction)\n",
        "b_image = GenerateTestingImage('/kaggle/input/vesuvius-challenge-ink-detection/test/b',b_prediction)"
      ],
      "metadata": {
        "id": "awAdehoNfEHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_output = torch.from_numpy(np.array(a_image)).gt(0).float().to(DEVICE)\n",
        "b_output = torch.from_numpy(np.array(b_image)).gt(0).float().to(DEVICE)\n",
        "\n"
      ],
      "metadata": {
        "id": "aVP4zBfVfED7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.4\n",
        "\n",
        "def rle(output):\n",
        "    pixels = np.where(output.flatten().cpu() > THRESHOLD, 1, 0).astype(np.uint8)\n",
        "    pixels[0] = 0\n",
        "    pixels[-1] = 0\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
        "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "metadata": {
        "id": "ZqhgAUFafD_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rle_output_a = rle(a_output)\n",
        "rle_output_b = rle(b_output)"
      ],
      "metadata": {
        "id": "RCj3bcYAfg14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Id,Predicted\\na,\" + rle_output_a + \"\\nb,\" + rle_output_b, file=open('/kaggle/working/submission.csv', 'w'))"
      ],
      "metadata": {
        "id": "-rrg0ynzfgyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cV8vYHuwfgvV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}